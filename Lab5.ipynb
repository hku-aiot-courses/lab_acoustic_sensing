{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8bc01f1",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and student ID below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME1 = \"\"\n",
    "NAME2 = \"\"\n",
    "NAME3 = \"\"\n",
    "ID1 = \"\" ## Your student id\n",
    "ID2 = \"\"\n",
    "ID3 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a6a44",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786d38dd-c42b-46c9-98cb-bbd84c2c62c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "237e034424f9f1fb156aae4a9a8a80c8",
     "grade": false,
     "grade_id": "cell-59931fe95bb55808",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "# Lab 5 Advanced Tasks (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5acf3f-4797-4516-845f-f58ce1fce81a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c67277a3a62d12a6fbb3c5e141a35ff3",
     "grade": false,
     "grade_id": "cell-360d7f5f5b84d2f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Previously, you have accomplished a easy distance measuring task using acoustic sensing. Actually this is a rough calculation, as you can see. There are many means to improve the robustness as well as correctness of the algorithm. Below we listed some of hints that may help you improve the performance. Things may remain unchanged even if you try some of these methods, but your shot counts. You are advised to write your findings in your report and show them in your presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bbaae8-2100-444b-894a-a175e7089e4a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f2b67ce887b238319b04e695e62551a",
     "grade": false,
     "grade_id": "cell-423b08c28923ddd3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Hint 1: Signal Processing\n",
    "\n",
    "Throughout our process, we attempt to get the frequency change. If we think from a signal processing aspective, multiple variables may make a difference:\n",
    "\n",
    "1. The bandwidth of FMCW.\n",
    "\n",
    "What if we change the bandwidth of the sent bandwidth? Could the situation become better or worse? To change that, you may need record the received signal on your own. Any speakers and microphones can do that. Please be aware that variables should be controlled in your conduct of the experiment.\n",
    "\n",
    "2. The frequency resolution\n",
    "\n",
    "You can refer to Lab 1 to see how we can improve the real resolution or FFT resolution. And observe the change of FFT curve and the peaks. See if there is any improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861cb12c-b938-461a-ac98-a7a225968e61",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19f8bd5970dd4ed535b9ccd7549b9037",
     "grade": false,
     "grade_id": "cell-bd57b9b037966c61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Hint 2: Hardware Offset\n",
    "\n",
    "Our data is recorded using a minidsp device connected to computer. Hardware offset may be introduced since the microphone and speaker may use separate oscillators. To avoid that, you can use your smartphones to collect the data. That is, you can make an program that can use the speakers and microphones simultaneously and save the sent and received data for further processing. \n",
    "\n",
    "Alternatively, if you are an expert, you can even program the whole distance-measuring algorithm to your mobile devices. You can show the real-time results on your screen. \n",
    "\n",
    "Note that since the task is optional, we do not provide extra support for you. However, the lab is assessed based on your contribution. Thus, even if you fail to make a very nice outcome, you are welcome to include them in your report and presentation. Again, every shot counts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398082d7-d467-4733-8e24-c9d7aad1f7d6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be659a7af69230a2934a876a281429c1",
     "grade": false,
     "grade_id": "cell-74b7dc6329cf5e08",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Hint 3: Synchronization\n",
    "\n",
    "Other than acquiring extra data, you are also encouraged to think about the synchronization problem. Approaches that we use is sysnchronization-sensitive. And huge offsets are introduced when we estimate the starting point. There are many mature means to enhance the performance. We hereby introduce some of them for your reference.\n",
    "\n",
    "1. Time Cross-correlation\n",
    "\n",
    "Suppose the original signal $S(t)$ and received signal $R(t)$, the cross-correlation is given by\n",
    "\n",
    "$$ \n",
    "\\text{corr}_{S,R}(i) = \\sum_{j = 1}^N S(j) R(i + j)\n",
    "$$\n",
    "\n",
    "And the goal is find the $i$ that maximize it.\n",
    "\n",
    "$$\n",
    "\\text{lag} = \\text{argmax}_i \\: \\text{corr}_{S,R}(i)\n",
    "$$\n",
    "\n",
    "The intuition of this method is to traverse all displacements. At the point where two signals coincide, their cross-correlation reaches maximum.\n",
    "<div align=center>\n",
    "<img src = \"https://makeabilitylab.github.io/physcomp/signals/ComparingSignals/assets/movies/CrossCorrelationAnimation_Robosub_EECS_WSU.gif\"></img>\n",
    "</div>\n",
    "\n",
    "2. Dynamic Time Warping (DTW) \n",
    "\n",
    "Dynamic time warping (DTW) is a method that computes the path between two signals that minimize the distance between the two signals. The greatest advantage of this method is that it can also deal with signals of different length. It is based on Dynamic Programming (DP). \n",
    "\n",
    "You can refer to this video [DTW](https://www.youtube.com/watch?v=_K1OsqCicBY) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0075dfc9-10b7-4aa1-8b01-e86d17d5c43c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0136ccf7a34809a17bbed18759ffe9e5",
     "grade": false,
     "grade_id": "cell-53c28d9fda16669c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Hint 4: Why FMCW? Why frequency change?\n",
    "\n",
    "In acoustic sensing community, there are many other waveforms and methods for distance measuring or other applications. You are encouraged to refer to the following papers ( You can find more). If you are fascinated, you can reproduce their work. You can also review them and summurize the methodologies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4f958-c7d9-40fb-8ddd-2a5c5dc7ae63",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed1a4bf6995c22756961c6441ab910b7",
     "grade": false,
     "grade_id": "cell-bd24cab9a2466048",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "- Chen, Huangxun, Wei Wang, Jin Zhang, and Qian Zhang. “EchoFace: Acoustic Sensor-Based Media Attack Detection for Face Authentication.” IEEE Internet of Things Journal 7, no. 3 (March 2020): 2152–59. https://doi.org/10.1109/JIOT.2019.2959203.\n",
    "\n",
    "- Chen, Huijie, Fan Li, Wan Du, Song Yang, Matthew Conn, and Yu Wang. “Listen to Your Fingers: User Authentication Based on Geometry Biometrics of Touch Gesture.” Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 4, no. 3 (September 4, 2020): 1–23. https://doi.org/10.1145/3411809.\n",
    "\n",
    "- Chen, Huijie, Fan Li, and Yu Wang. “EchoTrack: Acoustic Device-Free Hand Tracking on Smart Phones.” In IEEE INFOCOM 2017 - IEEE Conference on Computer Communications, 1–9, 2017. https://doi.org/10.1109/INFOCOM.2017.8057101.\n",
    "\n",
    "- Cheng, Haiming, and Wei Lou. “PD-FMCW: Push the Limit of Device-Free Acoustic Sensing Using Phase Difference in FMCW.” IEEE Transactions on Mobile Computing, 2022, 1–1. https://doi.org/10.1109/TMC.2022.3162631.\n",
    "\n",
    "- Cheng, Haiming, and Wei Lou. “Push the Limit of Device-Free Acoustic Sensing on Commercial Mobile Devices.” In IEEE INFOCOM 2021 - IEEE Conference on Computer Communications, 1–10, 2021. https://doi.org/10.1109/INFOCOM42981.2021.9488703.\n",
    "\n",
    "- Gong, Yanbin, Qian Zhang, Bobby H.P. NG, and Wei Li. “BreathMentor: Acoustic-Based Diaphragmatic Breathing Monitor System.” Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 6, no. 2 (July 7, 2022): 53:1-53:28. https://doi.org/10.1145/3534595.\n",
    "\n",
    "- Li, Dong, Jialin Liu, Sunghoon Ivan Lee, and Jie Xiong. “LASense: Pushing the Limits of Fine-Grained Activity Sensing Using Acoustic Signals.” Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 6, no. 1 (March 29, 2022): 21:1-21:27. https://doi.org/10.1145/3517253.\n",
    "\n",
    "- Lian, Jie, Jiadong Lou, Li Chen, and Xu Yuan. “EchoSpot: Spotting Your Locations via Acoustic Sensing.” Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 5, no. 3 (September 14, 2021): 113:1-113:21. https://doi.org/10.1145/3478095.\n",
    "\n",
    "- Liu, Jialin, Dong Li, Lei Wang, Fusang Zhang, and Jie Xiong. “Enabling Contact-Free Acoustic Sensing under Device Motion.” Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 6, no. 3 (September 7, 2022): 128:1-128:27. https://doi.org/10.1145/3550329.\n",
    "\n",
    "- Liu, Manni, Linsong Cheng, Kun Qian, Jiliang Wang, Jin Wang, and Yunhao Liu. “Indoor Acoustic Localization: A Survey.” Human-Centric Computing and Information Sciences 10, no. 1 (December 2020): 2. https://doi.org/10.1186/s13673-019-0207-4.\n",
    "\n",
    "- Mao, Wenguang, Wei Sun, Mei Wang, and Lili Qiu. “DeepRange: Acoustic Ranging via Deep Learning.” Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 4, no. 4 (December 17, 2020): 1–23. https://doi.org/10.1145/3432195.\n",
    "\n",
    "- Mollyn, Vimal, Karan Ahuja, Dhruv Verma, Chris Harrison, and Mayank Goel. “SAMoSA: Sensing Activities with Motion and Subsampled Audio.” Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 6, no. 3 (September 7, 2022): 132:1-132:19. https://doi.org/10.1145/3550284.\n",
    "\n",
    "- Nandakumar, Rajalakshmi, Shyamnath Gollakota, and Nathaniel Watson. “Contactless Sleep Apnea Detection on Smartphones.” In Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services, 45–57. Florence Italy: ACM, 2015. https://doi.org/10.1145/2742647.2742674.\n",
    "\n",
    "- Qian, Kun, Chenshu Wu, Fu Xiao, Yue Zheng, Yi Zhang, Zheng Yang, and Yunhao Liu. “Acousticcardiogram: Monitoring Heartbeats Using Acoustic Signals on Smart Devices.” In IEEE INFOCOM 2018 - IEEE Conference on Computer Communications, 1574–82. Honolulu, HI: IEEE, 2018. https://doi.org/10.1109/INFOCOM.2018.8485978.\n",
    "\n",
    "- Seflek, Ibrahim, Yunus Emre Acar, and Ercan Yaldiz. “Small Motion Detection and Non-Contact Vital Signs Monitoring with Continuous Wave Doppler Radars.” Elektronika Ir Elektrotechnika 26, no. 3 (June 27, 2020): 54–60. https://doi.org/10.5755/j01.eie.26.3.25810.\n",
    "\n",
    "- Wan, Haoran, Shuyu Shi, Wenyu Cao, Wei Wang, and Guihai Chen. “RespTracker: Multi-User Room-Scale Respiration Tracking with Commercial Acoustic Devices.” In IEEE INFOCOM 2021 - IEEE Conference on Computer Communications, 1–10. Vancouver, BC, Canada: IEEE, 2021. https://doi.org/10.1109/INFOCOM42981.2021.9488881.\n",
    "\n",
    "- Wang, Anran, Dan Nguyen, Arun R. Sridhar, and Shyamnath Gollakota. “Using Smart Speakers to Contactlessly Monitor Heart Rhythms.” Communications Biology 4, no. 1 (March 9, 2021): 1–12. https://doi.org/10.1038/s42003-021-01824-9.\n",
    "\n",
    "- Wang, Penghao, Ruobing Jiang, and Chao Liu. “Amaging: Acoustic Hand Imaging for Self-Adaptive Gesture Recognition.” In IEEE INFOCOM 2022 - IEEE Conference on Computer Communications, 80–89, 2022. https://doi.org/10.1109/INFOCOM48880.2022.9796906.\n",
    "\n",
    "- Wang, Tianben, Daqing Zhang, Yuanqing Zheng, Tao Gu, Xingshe Zhou, and Bernadette Dorizzi. “C-FMCW Based Contactless Respiration Detection Using Acoustic Signal.” Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 1, no. 4 (January 8, 2018): 1–20. https://doi.org/10.1145/3161188.\n",
    "\n",
    "- Wang, Wei, Alex X. Liu, and Ke Sun. “Device-Free Gesture Tracking Using Acoustic Signals.” In Proceedings of the 22nd Annual International Conference on Mobile Computing and Networking, 82–94. MobiCom ’16. New York, NY, USA: Association for Computing Machinery, 2016. https://doi.org/10.1145/2973750.2973764.\n",
    "\n",
    "- Xie, Wentao, Runxin Tian, Jin Zhang, and Qian Zhang. “Noncontact Respiration Detection Leveraging Music and Broadcast Signals.” IEEE Internet of Things Journal 8, no. 4 (February 2021): 2931–42. https://doi.org/10.1109/JIOT.2020.3021915.\n",
    "\n",
    "- Xie, Yadong, Fan Li, Yue Wu, and Yu Wang. “HearFit: Fitness Monitoring on Smart Speakers via Active Acoustic Sensing.” In IEEE INFOCOM 2021 - IEEE Conference on Computer Communications, 1–10, 2021. https://doi.org/10.1109/INFOCOM42981.2021.9488811.\n",
    "\n",
    "- Xu, Xiangyu, Jiadi Yu, Yingying Chen, Yanmin Zhu, Linghe Kong, and Minglu Li. “BreathListener: Fine-Grained Breathing Monitoring in Driving Environments Utilizing Acoustic Signals.” In Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services, 54–66. Seoul Republic of Korea: ACM, 2019. https://doi.org/10.1145/3307334.3326074.\n",
    "\n",
    "- Yun, Sangki, Yi-Chao Chen, Huihuang Zheng, Lili Qiu, and Wenguang Mao. “Strata: Fine-Grained Acoustic-Based Device-Free Tracking.” In Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services, 15–28. Niagara Falls New York USA: ACM, 2017. https://doi.org/10.1145/3081333.3081356."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7362fe6-947f-44af-ac17-f6d18a06aba2",
   "metadata": {},
   "source": [
    "## How to submit your code or other materials in Lab5?\n",
    "\n",
    "Since it is an optional task, you can do whatever you want. If you just make some adjustments or adventures, you can write your code here by creating new cells. And if what you want to convey is enough in your two-page report, just submit your report.\n",
    "\n",
    "However, if you implement something big, say a project, you will be recommended to send all your code and a README.md showing how to run your project as well as screenshoots of your outcomes to TA's email : slyu@cs.hku.hk or shenglyu@connect.hku.hk. That is also for report. If you think what you have done is more than 2-page, you can send your report of Lab 5 to the above email. Note that in either case, you still need to upload your two-pages report.\n",
    "\n",
    "Lab 5 is not restricted by the regulation about public repositories. You are welcome to upload your Lab 5 to your Github. If you do so, you can drop me the link. "
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {},
   "style": "ieee-transactions-on-mobile-computing.csl"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
